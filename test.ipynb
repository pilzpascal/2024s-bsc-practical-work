{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:20:34.596026Z",
     "start_time": "2024-08-30T14:20:34.586847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ],
   "id": "66941f15738a7c47",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:22:50.569725Z",
     "start_time": "2024-08-30T14:22:50.564300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TRAIN_SIZE = 20\n",
    "VAL_SIZE = 100\n",
    "POOL_SIZE = 60_000 - (TRAIN_SIZE + VAL_SIZE)\n",
    "print(f\"train size: {TRAIN_SIZE:_}, val size: {VAL_SIZE:_}, pool size: {POOL_SIZE:_}\")\n",
    "\n",
    "DATA_PATH = '/Users/pascalpilz/Documents/Bsc Thesis/data/mnist/'\n",
    "MODEL_SAVE_PATH = '/Users/pascalpilz/Documents/Bsc Thesis/models/'\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ],
   "id": "714e342b5bb625d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 20, val size: 100, pool size: 59_880\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Loading",
   "id": "551f1e14786a5a38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:58:06.085800Z",
     "start_time": "2024-08-30T14:57:58.415737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     # we do this bc the images are 28x28 but the network expects 32x32\n",
    "     torchvision.transforms.Pad(2),\n",
    "     # 0.10003718,  are mean and std of train set after padding (without padding it is 0.1307 and 0.3081)\n",
    "     torchvision.transforms.Normalize((0.10003718,), (0.2752173,)),\n",
    "     ])\n",
    "\n",
    "# getting the test and train set\n",
    "mnist_train = torchvision.datasets.MNIST(root=DATA_PATH, train=True, transform=transform)\n",
    "mnist_test = torchvision.datasets.MNIST(root=DATA_PATH, train=False, transform=transform)\n",
    "\n",
    "# splitting train further into train and val\n",
    "train, val = torch.utils.data.random_split(mnist_train, [TRAIN_SIZE + POOL_SIZE, VAL_SIZE])\n",
    "\n",
    "# creating data loaders\n",
    "# having batch size equal to the size of the dataset to get the whole dataset in one batch\n",
    "# enables us to get the whole dataset at once when iterating over the loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=len(train), shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=len(val), shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=len(mnist_test), shuffle=True)\n",
    "\n",
    "X_train_all, y_train_all = next(iter(train_loader))\n",
    "X_val, y_val = next(iter(val_loader))\n",
    "X_test, y_test = next(iter(test_loader))\n",
    "\n",
    "# creating a random but balanced initial training set\n",
    "idx = []\n",
    "for num in range(10):\n",
    "    indices = torch.where(y_train_all == num)[0]\n",
    "    idx += list(np.random.choice(indices, 2, replace=False))\n",
    "idx = torch.tensor(idx)\n",
    "\n",
    "X_train = X_train_all[idx]\n",
    "y_train = y_train_all[idx]\n",
    "\n",
    "X_pool = X_train_all[~torch.isin(torch.arange(len(X_train_all)), idx)]\n",
    "y_pool = y_train_all[~torch.isin(torch.arange(len(X_train_all)), idx)]\n",
    "\n",
    "print(f\"train .. size: {len(X_train):6_}, mean: {X_train.mean():6.3f}, std: {X_train.std():6.3f}\")\n",
    "print(f\"val .... size: {len(X_val):6_}, mean: {X_val.mean():6.3f}, std: {X_val.std():6.3f}\")\n",
    "print(f\"pool ... size: {len(X_pool):6_}, mean: {X_pool.mean():6.3f}, std: {X_pool.std():6.3f}\")\n",
    "print(f\"test ... size: {len(X_test):6_}, mean: {X_test.mean():6.3f}, std: {X_test.std():6.3f}\")\n",
    "\n",
    "plt.hist([y_train, y_val, y_pool, y_test], bins=range(0, 11), density=True, label=['train', 'val', 'pool', 'test'])\n",
    "\n",
    "# set x ticks\n",
    "plt.xticks(np.linspace(0.5, 9.5, 10), np.arange(0, 10))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "val_set = torch.utils.data.TensorDataset(X_val, y_val) \n",
    "test_set = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=True)"
   ],
   "id": "56b7b2fd0fc0fb67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train .. size:     20, mean:  0.002, std:  1.004\n",
      "val .... size:    100, mean: -0.004, std:  0.997\n",
      "pool ... size: 59_880, mean:  0.000, std:  1.000\n",
      "test ... size: 10_000, mean:  0.005, std:  1.008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "89cbe0838f4f82b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:33:36.329051Z",
     "start_time": "2024-08-30T14:33:36.324540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "         super(LeNet, self).__init__()\n",
    "         self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "         self.pool = nn.MaxPool2d(2)\n",
    "         self.do1 = nn.Dropout(0.25)  # 0.25 chosen as in Gal et al. 2016\n",
    "         self.do2 = nn.Dropout(0.5)  # 0.5 chosen as in Gal et al. 2016\n",
    "         self.fc1 = nn.Linear(16 * 5 * 5, 120)  # images are 5x5 with 16 channels\n",
    "         self.fc2 = nn.Linear(120, 84)\n",
    "         self.fc3 = nn.Linear(84, 10)\n",
    "         \n",
    "    def forward(self, x):               # x.shape = (b, 32, 32), where b is batch size\n",
    "        c1 = F.relu(self.conv1(x))      # c1.shape = (b, 6, 28, 28)\n",
    "        p2 = self.pool(c1)              # p2.shape = (b, 6, 12, 12)\n",
    "        c3 = F.relu(self.conv2(p2))     # c3.shape = (b, 16, 10, 10)\n",
    "        p4 = self.pool(c3)              # p4.shape = (b, 16, 5, 5)\n",
    "        p5 = torch.flatten(p4, 1)       # p5.shape = (b, 16*5*5) = (b, 400)\n",
    "        d6 = self.do1(p5)               # d6.shape = (b, 400)\n",
    "        f7 = F.relu(self.fc1(d6))       # f6.shape = (b, 120)\n",
    "        d8 = self.do2(f7)               # d8.shape = (b, 12)\n",
    "        f9 = F.relu(self.fc2(d8))       # f9.shape = (b, 84)\n",
    "        output = self.fc3(f9)           # output.shape = (b, 10)\n",
    "        return output"
   ],
   "id": "9cdc6433a738499d",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training and Testing Functions",
   "id": "239616c036679337"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T15:57:27.987151Z",
     "start_time": "2024-08-30T15:57:27.982348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model,\n",
    "                    optimizer,\n",
    "                    loss_fn,\n",
    "                    train_loader,\n",
    "                    epoch_index,\n",
    "                    tb_writer,\n",
    "                    write_at=1000,\n",
    "                    verbose=False):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % write_at == write_at-1:\n",
    "            last_loss = running_loss / write_at # loss per batch\n",
    "            if verbose:\n",
    "                print(f'  batch {i + 1:7_d} train loss: {last_loss:6.4f}')\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ],
   "id": "5b5dc12bff36bf85",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T16:13:11.614014Z",
     "start_time": "2024-08-30T16:13:11.608212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_training(model,\n",
    "                 train_loader,\n",
    "                 val_loader,\n",
    "                 optimizer,\n",
    "                 loss_fn,\n",
    "                 n_epochs=5,\n",
    "                 verbose=False):\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    writer = SummaryWriter(f'runs/mnist_trainer_{timestamp}')\n",
    "    model_path = MODEL_SAVE_PATH + str(timestamp) + '/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    best_vloss = np.inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if verbose:\n",
    "            print('EPOCH {}:'.format(epoch + 1))\n",
    "    \n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(model=model,\n",
    "                                   optimizer=optimizer,\n",
    "                                   loss_fn=loss_fn,\n",
    "                                   train_loader=train_loader,\n",
    "                                   epoch_index=epoch,\n",
    "                                   tb_writer=writer,\n",
    "                                   write_at=5000,\n",
    "                                   verbose=verbose)\n",
    "    \n",
    "        running_vloss = 0.0\n",
    "        model.eval()\n",
    "    \n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, (vinputs, vlabels) in enumerate(val_loader):\n",
    "                voutputs = net(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "                running_vloss += vloss\n",
    "    \n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        if verbose:\n",
    "            print(f'LOSS train {avg_loss:6.5f} valid {avg_vloss:6.4f}\\n')\n",
    "    \n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                           {'Training': avg_loss, 'Validation': avg_vloss},\n",
    "                           epoch + 1)\n",
    "        writer.flush()\n",
    "    \n",
    "        # track the best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_path = model_path + f'model_{timestamp}_{epoch}'\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            \n",
    "    if verbose:\n",
    "        print('Done.')\n",
    "    return model_path"
   ],
   "id": "4cc0c48efced3b8",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T16:04:02.433821Z",
     "start_time": "2024-08-30T16:04:02.427316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_acc(model, dataloader):\n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "    predications = []\n",
    "    \n",
    "    for i, (tinputs, tlabels) in enumerate(dataloader):\n",
    "        toutputs = net(tinputs)\n",
    "        toutputs = torch.argmax(toutputs, dim=1)\n",
    "        running_corrects += torch.sum(toutputs == tlabels.data)\n",
    "        predications += toutputs.tolist()\n",
    "        \n",
    "    acc = running_corrects.float() / (len(dataloader) * 4)\n",
    "    return acc"
   ],
   "id": "69b84703572f6596",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Acquisition Functions",
   "id": "4cf4f158f9d454b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T15:36:04.451260Z",
     "start_time": "2024-08-30T15:36:04.444228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def perform_acquisition(model, acquisition_function, X_train, y_train, X_pool, y_pool):\n",
    "    idx = acquisition_function(model, X_pool)\n",
    "    \n",
    "    chosen_X_pool = X_pool[idx]\n",
    "    chosen_y_pool = y_pool[idx]\n",
    "    \n",
    "    new_X_train = torch.concatenate([X_train, chosen_X_pool], 0)\n",
    "    new_y_train = torch.concatenate([y_train, chosen_y_pool], 0)\n",
    "    \n",
    "    new_X_pool = X_pool[~torch.isin(torch.arange(len(X_pool)), idx)]\n",
    "    new_y_pool = y_pool[~torch.isin(torch.arange(len(y_pool)), idx)]\n",
    "    \n",
    "    return new_X_train, new_y_train, new_X_pool, new_y_pool\n",
    "\n",
    "def random(model, X_pool, size=100):\n",
    "    idx = np.random.choice(range(len(X_pool)), size=size, replace=False)\n",
    "    idx = torch.from_numpy(idx)\n",
    "    return idx"
   ],
   "id": "fd50050bc75765b5",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experiments",
   "id": "d6f7d0ab4975339a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T16:06:01.149034Z",
     "start_time": "2024-08-30T16:06:01.143507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = LeNet()\n",
    "print(net)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(f\"number of trainable parameters: {params}\")"
   ],
   "id": "f94d3df5ddb7553b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (do1): Dropout(p=0.25, inplace=False)\n",
      "  (do2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "number of trainable parameters: 61706\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T16:10:55.257820Z",
     "start_time": "2024-08-30T16:10:55.080169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set = torch.utils.data.TensorDataset(\n",
    "    torch.concatenate([X_train, X_pool, X_val], 0),\n",
    "    torch.concatenate([y_train, y_pool, y_val], 0)\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ],
   "id": "3c71667a798c6783",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T16:13:11.605931Z",
     "start_time": "2024-08-30T16:10:57.280018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = run_training(net,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader,\n",
    "                    optimizer=optimizer,\n",
    "                    loss_fn=loss_fn,\n",
    "                    n_epochs=5,\n",
    "                    verbose=True)"
   ],
   "id": "7389955575cb4bf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch   5_000 train loss: 0.6871\n",
      "  batch  10_000 train loss: 0.2184\n",
      "  batch  15_000 train loss: 0.1771\n",
      "LOSS train 0.17706 valid 0.0234\n",
      "\n",
      "Done.\n",
      "EPOCH 2:\n",
      "  batch   5_000 train loss: 0.1489\n",
      "  batch  10_000 train loss: 0.1337\n",
      "  batch  15_000 train loss: 0.1236\n",
      "LOSS train 0.12356 valid 0.0495\n",
      "\n",
      "Done.\n",
      "EPOCH 3:\n",
      "  batch   5_000 train loss: 0.1129\n",
      "  batch  10_000 train loss: 0.1061\n",
      "  batch  15_000 train loss: 0.0996\n",
      "LOSS train 0.09962 valid 0.0024\n",
      "\n",
      "Done.\n",
      "EPOCH 4:\n",
      "  batch   5_000 train loss: 0.1024\n",
      "  batch  10_000 train loss: 0.0919\n",
      "  batch  15_000 train loss: 0.0878\n",
      "LOSS train 0.08776 valid 0.0152\n",
      "\n",
      "Done.\n",
      "EPOCH 5:\n",
      "  batch   5_000 train loss: 0.0916\n",
      "  batch  10_000 train loss: 0.0833\n",
      "  batch  15_000 train loss: 0.0811\n",
      "LOSS train 0.08115 valid 0.0091\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T16:17:49.829528Z",
     "start_time": "2024-08-30T16:17:47.969607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# path = MODEL_SAVE_PATH + '20240830_181057/model_20240830_181057_0model_20240830_181057_2'\n",
    "best_model = LeNet()\n",
    "best_model.load_state_dict(torch.load(path, weights_only=True))\n",
    "acc = get_acc(best_model, test_loader)\n",
    "print(f'accuracy of best model: {acc:.4f}')"
   ],
   "id": "8568bbf41892db0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of best model: 0.9879\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "running_X_train = X_train\n",
    "running_y_train = y_train\n",
    "\n",
    "running_X_pool = X_pool\n",
    "running_y_pool = y_pool\n",
    "\n",
    "for i in range(10):\n",
    "    train_set = torch.utils.data.TensorDataset(running_X_train, running_y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True)"
   ],
   "id": "3bf17c75b773c9b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ff60dbd80f11eb3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
